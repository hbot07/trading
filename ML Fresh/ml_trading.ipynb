{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch historical stock data using yfinance\n",
    "def fetch_data(stock_symbol):\n",
    "    # Define the stock symbol and the period for which we want the data\n",
    "    period = \"1d\"  # Last 7 days\n",
    "    interval = \"1m\"  # 1-minute intervals\n",
    "\n",
    "    # Use yfinance to download the data\n",
    "    stock_data = yf.download(stock_symbol, period=period, interval=interval)\n",
    "    return stock_data\n",
    "\n",
    "# Process the data to create features and labels\n",
    "def prepare_data(stock_data, look_forward=10):\n",
    "    # Calculate the future price after `look_forward` minutes (our label)\n",
    "    stock_data['Future_Price'] = stock_data['Close'].shift(-look_forward)\n",
    "\n",
    "    # Drop the last `look_forward` rows since they don't have a future price\n",
    "    stock_data = stock_data[:-look_forward]\n",
    "\n",
    "    return stock_data\n",
    "\n",
    "# Replace 'AAPL' with the symbol of the stock you are interested in\n",
    "stock_symbol = 'AAPL'\n",
    "raw_data = fetch_data(stock_symbol)\n",
    "prepared_data = prepare_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.19.5 in /Users/hbot07/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/hbot07/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.11.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.1.post1 threadpoolctl-3.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cx/8v11zwh97cxgdgt_ph13_56r0000gn/T/ipykernel_69644/2196208453.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[['Close', 'Volume', 'Future_Price']] = scaler.fit_transform(data[['Close', 'Volume', 'Future_Price']])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_data(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data[['Close', 'Volume', 'Future_Price']] = scaler.fit_transform(data[['Close', 'Volume', 'Future_Price']])\n",
    "    return data, scaler\n",
    "\n",
    "prepared_data, scaler = normalize_data(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, test_size=0.2):\n",
    "    # Calculate the index to split the data\n",
    "    split_idx = int(len(data) * (1 - test_size))\n",
    "    train = data[:split_idx]\n",
    "    test = data[split_idx:]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train_data, test_data = split_data(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x = data[['Close', 'Volume']].iloc[i:(i + sequence_length)].values\n",
    "        y = data['Future_Price'].iloc[i + sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "sequence_length = 60  # number of minutes to look back\n",
    "X_train, y_train = create_sequences(train_data, sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 01:58:25.716448: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 01:58:30.104785: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-15 01:58:30.104848: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = build_model((X_train.shape[1], X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 01:58:41.507843: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-15 01:58:41.907295: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n",
      "2024-03-15 01:58:42.386227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-15 01:58:43.476508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-15 01:58:44.609899: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-15 01:58:45.072848: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - ETA: 0s - loss: 0.0294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 01:58:53.820978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-15 01:58:54.046706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-15 01:58:54.224151: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 19s 163ms/step - loss: 0.0294 - val_loss: 0.0058\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 7s 108ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 7s 107ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 7s 111ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 7s 108ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 6/20\n",
      "66/66 [==============================] - 7s 111ms/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 7s 110ms/step - loss: 0.0053 - val_loss: 0.0080\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 7s 108ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 7s 113ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 7s 105ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 11/20\n",
      "66/66 [==============================] - 7s 103ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 12/20\n",
      "66/66 [==============================] - 7s 104ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 13/20\n",
      "66/66 [==============================] - 7s 104ms/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 14/20\n",
      "66/66 [==============================] - 7s 103ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 15/20\n",
      "66/66 [==============================] - 7s 104ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 16/20\n",
      "66/66 [==============================] - 7s 106ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 17/20\n",
      "66/66 [==============================] - 7s 104ms/step - loss: 0.0050 - val_loss: 0.0073\n",
      "Epoch 18/20\n",
      "66/66 [==============================] - 7s 101ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 19/20\n",
      "66/66 [==============================] - 7s 101ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 20/20\n",
      "66/66 [==============================] - 7s 101ms/step - loss: 0.0045 - val_loss: 0.0044\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 38ms/step - loss: 0.0044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004379523452371359"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicted price: 172.96384414888144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/hbot07/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "\n",
    "# Define your stock symbol and fetch data\n",
    "stock_symbol = 'AAPL'\n",
    "period = '60m'  # Lookback period to match your training sequence length\n",
    "interval = '1m'\n",
    "new_data = yf.download(stock_symbol, period=period, interval=interval)\n",
    "\n",
    "# Assume sequence_length is defined (same as your training data)\n",
    "sequence_length = 60\n",
    "\n",
    "# Prepare the latest data for prediction\n",
    "last_sequence = new_data[['Close', 'Volume']].tail(sequence_length).values\n",
    "\n",
    "# If your scaler was initially fitted with a dummy 'Future_Price', add a dummy column to match the shape\n",
    "dummy_future_price = np.zeros((last_sequence.shape[0], 1))  # Create a column of zeros\n",
    "last_sequence_with_dummy = np.hstack((last_sequence, dummy_future_price))  # Add this column to your sequence\n",
    "\n",
    "# Scale the data\n",
    "last_sequence_scaled = scaler.transform(last_sequence_with_dummy)\n",
    "\n",
    "# Remove the dummy 'Future_Price' column after scaling\n",
    "last_sequence_scaled = last_sequence_scaled[:, :-1]  # Remove the dummy column, keeping only 'Close' and 'Volume'\n",
    "\n",
    "# Reshape data for the model\n",
    "last_sequence_scaled = np.expand_dims(last_sequence_scaled, axis=0)  # Add the batch dimension\n",
    "\n",
    "# Predict using the model\n",
    "predicted_price_scaled = model.predict(last_sequence_scaled)\n",
    "\n",
    "# If necessary, reverse scaling on predicted price\n",
    "# Prepare a dummy array for reverse scaling process\n",
    "dummy_array = np.zeros((1, len(scaler.scale_)))  # Create a dummy array with the correct shape\n",
    "dummy_array[:, -1] = predicted_price_scaled.squeeze()  # Place the predicted price in the correct column\n",
    "\n",
    "# Reverse the scaling\n",
    "predicted_price = scaler.inverse_transform(dummy_array)[:, -1]  # Extract the price from the scaled array\n",
    "\n",
    "# Output the predicted price\n",
    "print(\"Predicted price:\", predicted_price[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
